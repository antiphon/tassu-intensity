---
title: "Wolf observations, rough intensity vol. 2.8: Diagnostics v2.0"
author: "Tuomas Rajala"
date : "`r Sys.Date()`"
output:
  html_document:
    toc: true
    code_folding: hide
    fig_caption: true
    number_sections: true
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(ggplot2)
library(patchwork)
library(dplyr)
library(tidyr)
library(raster)
library(mgcv)
library(parallel)
library(sf)
theme_set(theme_bw())
knitr::opts_chunk$set(fig.width=9, fig.height=3, echo=TRUE, message=FALSE, warning=FALSE)
```

- v2.0: standardized cell counts-diagnostics ($\chi^2$ testing)

Tarkastellaan mallin tuottamia lukumääräennusteita.

- oletataan että paikalla on keskikokoinen reviiri

```{r}
crs1 <- 3067
crs1_c <- paste0("EPSG:", crs1)

fin <- readRDS("../data/finland.rds")
# Drop lappi from geometries
box1 <- st_bbox(c(xmin=0, xmax=100000000, ymin=0, ymax = max(72e5 + 30000)), crs=st_crs(fin))
fin1 <- st_crop(fin, box1)
ex1 <- raster::extent(sf::st_bbox(fin1)[c(1,3,2,4)])


fit <- readRDS("processed/poisson_regression_bamfit-v2.8.rds")
mdf <- readRDS("processed/celdat-v2.6.rds") %>% filter( vuosi < 2020)

c20 <- c20s <- readRDS("processed/corine8s-v1.rds")
regions <- readRDS("processed/territories-v1.rds")

# new
droad0 <- crop(stack("../data/digiroad_luokka12_1x1km_2021-04-14.grd"),  ex1)
projection(droad0) <- crs1_c
droad1 <- setNames(droad0, "droad.cl12")
```




Malli: 

```{r}
phihat <- sum(residuals( fit, type = "pearson" )^2) / df.residual(fit)

ss <- summary(fit, dispersion = phihat) 
#
print(ss)
cat("Overdispersion phi = ", phihat, "\n")
```


Reviirien keskiarvo

```{r}
area_km2_mean <- median(mdf$area_km2)
area_km2_mean
```

Kertoimet, luottamusvälit, natural scale:

```{r}
# nice function
q95 <- function(x){c(mean=mean(x), sd=sd(x), quantile(x, prob = c(0.025, 0.975)))}
# use sampling because why not.
cifun <- function(myl, w = 1) 
  rbind(log = q95(     w * rnorm(100000, myl[1], myl[2]) ),
        nat = q95( exp(w * rnorm(100000, myl[1], myl[2])) )) %>% 
  as_tibble(rownames = "scale")
reorder_nat <- function(...) filter(..., scale == "nat") %>% 
  dplyr::select(-scale) %>% dplyr::select(coef, everything())


allc <- lapply(1:nrow(ss$p.table), function(i) cifun(ss$p.table[i,]) %>% mutate(coef = rownames(ss$p.table)[i])) %>% bind_rows()

natc  <- allc %>% reorder_nat()

knitr::kable(natc %>% filter(grepl("yearf", coef)))
knitr::kable(natc %>% filter(grepl("monthf", coef)))
```

For corine, effect of in-case-of-1sd-change:

```{r}
rn <- rownames(ss$p.table)
#c20_sds <- c(apply(cbind(c20[], droad1[]),  2, na.rm=T, sd))
c20_sds <- c(apply(cbind(c20[], droad1[]),  2, na.rm=T, sd)) * 0 + 0.01
c20i <- grepl("c18.|droad.cl12", rn) %>% which()

c20c <- lapply(c20i, function(i) {
  w <- pmatch(rn[i] %>% gsub(pat="c18[.]", rep=""), names(c20_sds))
  cifun(ss$p.table[i,], w = c20_sds[w]) %>% mutate(coef = rn[i])
  })%>% bind_rows()
natc20 <- c20c %>% reorder_nat()

knitr::kable(natc20)

```

Spew out a string:

```{r}
txt <- ""
for(i in 1:nrow(natc20)) txt <- paste0(txt,
                                      sprintf("%s %3.0f%% ([%3.0f,%3.0f])", 
                                              gsub("c18[.]", "", natc20$coef[i]), 
                                              100*(natc20$mean[i]-1),
                                              100*(natc20$`2.5%`[i]-1),
                                              100*(natc20$`97.5%`[i]-1) ),
                                      "; ")
print(txt)

```


# Aika

## Effects

Yearly effects:


```{r}
sum1 <- ss
coefs <- sum1$p.table
cnames <- rownames(coefs)
vix <- grepl("year", cnames)
S <-  sum1$cov.scaled
vixS <- grepl("yearf", rownames(S))
vS <-  S[vixS, vixS]
AM <- t(rep(1, sum(vix)))/sum(vix)

out <- list(year_effect = coefs %>% as_tibble(rownames="coef") %>% filter(grepl("yearf", coef)))
out$year_effect %>% mutate(coef = gsub("wolf_yearf",  "", coef), estimate = Estimate, sd = `Std. Error` ) %>%
  ggplot(aes(coef, estimate))+ 
  geom_pointrange(aes(ymin = estimate - 2*sd, 
                      ymax = estimate+2*sd)) + 
  theme(axis.text.x = element_text(angle=30, hjust=1))
```

Compute the average year effect:

```{r}
myl <- c(estimate =  AM%*%coefs[vix,1], sd = sqrt( AM%*%vS%*%t(AM) ) )  
mean_year_effect <- cifun(myl)
      

out$mean_year_effect <- mean_year_effect

knitr::kable(mean_year_effect, digits=3)

```

Then monthly effects follow. Note wolfmonth=1 (April) has baseline value 0. 

```{r}
kix <- grepl("monthf", cnames)
my <- out$month_effects <- 
  lapply(which(kix), function(i)
    cifun(coefs[i, 1:2]) %>% 
  mutate(wolf_month = sprintf("%02i", sum(kix[1:i]) + 1 )) ) %>% bind_rows()

print(out$month_effects)

out$month_effects %>%  
  ggplot(aes(wolf_month, mean))+ 
  geom_pointrange(aes(ymin = `2.5%`, 
                      ymax = `97.5%`)) + 
  facet_wrap(~scale, scales = "free_y")

knitr::kable(out$month_effects %>% filter(scale == "nat"), digits = 2)
```



## Standardized cell counts and predictions (i.e. Pearson residuals under Poisson model)

Aggregoidaan havaintolukumäärät kuukauden paloihin, ja sitten verrataan ennusteisiin. Skaalataan, eli saadaan lukuja

$$r_l = \frac{y_l - \eta_l}{\sigma_l}$$
where 

- $y_l = \sum_{k\in G_l}y_k$ 
- $\eta_l = \sum_{k\in G_l}\hat y_k$ 
- $\sigma_l = \sqrt{\hat\phi\eta_l}$

## Alkuperäinen gridi, ei aggregoitu, kaikki data

```{r}
# Ensin alkuperäisessä gridissa
mdf <- mdf %>% mutate(time = mean.tdate,
                      yearmonth = sprintf("%i-%02i", vuosi, kk))


# Ennuste v havainnot
pred_o <- predict(fit, se = TRUE)

mom_o <-do.call(cbind, pred_o)
mom_o[,2] <- mom_o[,2] * sqrt(phihat)
lohi <- cbind(exp(-2*mom_o[,2]), 1, exp(2*mom_o[,2])) * exp(mom_o[,1]+0.5*mom_o[,2]^2) 

# should be the same as
# lohi <- apply(mom_o, 1, function(x)
#   function(x) {
#     v <- rnorm(100, x[1], x[2]) 
#     q <- quantile(v, p=c(0.025, 0.975))
#     c(q[1], mean(v), q[2])
#   } )

mdf <- mutate(mdf, 
              pred    = lohi[,2],
              pred_lo = lohi[,1],
              pred_hi = lohi[,3],
              pearson = (nsusi - pred)/(phihat * sqrt(pred)),
              year = vuosi,
              month = kk)


```

Cell data centers in time

```{r}
mdf %>% ggplot() + 
  geom_histogram(aes(time), bins=100) +
    scale_x_datetime(date_breaks = "1 year")

```

```{r}
mdf %>% pivot_longer(c(nsusi, pred)) %>%
  ggplot() +
  geom_histogram(aes(round(value), fill = name),
                 position = position_dodge(),
                bins = 100)
```

this is mad...


## Koko ajanjakso

```{r}

# Ennuste
temp_df <- mdf %>% group_by(year, month, time, yearmonth) %>%
  summarise(nobs = sum(nsusi),
            pred = sum(pred),
            sigma = sqrt( sum(pred) ) * phihat,
            pearson = (nobs - pred)/sigma,
            pred_hi = sum(pred_hi),
            pred_lo = sum(pred_lo))

```

Ennuste v havainnot, rounded predictions:

```{r}
temp_df %>% pivot_longer(pred:nobs) %>%
  ggplot() + 
  geom_histogram(aes(round(value) , 
                     fill = name), position = position_dodge(), 
                 bins = 50)
```


```{r}
pred_tdf1 <- temp_df %>% filter( year < 2020 ) # 

pred_tdf1 %>% pivot_longer(pred:nobs) %>%
  ggplot(aes(time, y = value)) +
  geom_ribbon(aes(time, ymin =pred_lo, ymax = pred_hi), alpha = .2) +
  geom_line(aes(linetype = name, col = name), size=1)  + 
  geom_point(aes(col = name)) +
  theme(legend.position = "bottom") +
  scale_x_datetime(date_breaks = "1 year")
```

- hankala nähdä mitä tapahtuu ennen 2017
- 2017->: 
  - yliennuste kohtalainen 2017&2019, 2018 paremmin kohdalla

Pearson residuaalit:

```{r}
pred_tdf1 %>% 
  ggplot(aes(time)) +
  geom_hline(yintercept = 0) + 
  geom_line(aes(y = pearson), col = 2, lwd=1)  +
  scale_x_datetime(date_breaks = "1 year") + 
  geom_hline(yintercept = c(-2,2)) + 
  ylim(c(-3,3))
```

- Vain muutama hetki menee ulos

Vuosittain:

```{r, fig.height=5, fig.width=10}
pred_tdf1 %>% #pivot_longer(pred:obs) %>%
  ggplot(aes(month, y = pearson)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  theme(legend.position = "bottom")+ 
  facet_wrap(~year, ncol = 5)
```

By months
```{r, fig.height=5, fig.width=10}
pred_tdf1 %>% #pivot_longer(pred:obs) %>%
  ggplot(aes(month, y = pearson)) +
  geom_text(aes(label = year, col = factor(year)), size = 3) +
  geom_hline(yintercept = 0) + 
  guides(col = "none") + 
  theme(legend.position = "bottom")
```




## Prior to 2016

```{r}
pred_tdf1 <- temp_df %>% filter( time < "2016-03-05")
pred_tdf1 %>% pivot_longer(pred:nobs) %>%
  ggplot(aes(time, y = value, col = name)) +
  geom_line(aes(linetype = name), size=1.5)  + 
  geom_point() +
  geom_ribbon(data = pred_tdf1, 
              aes(time, y=NULL, col = NULL, 
                  ymin = pred_lo, ymax = pred_hi), alpha = .1)+ 
  theme(legend.position = "bottom")+ 
  scale_x_datetime(date_breaks = "1 year")
```

difference

```{r}
pred_tdf1 %>% 
  ggplot(aes(time)) +
  geom_hline(yintercept = 0) + 
  geom_line(aes(y = pred - nobs), col = 2, lwd=1)  +
  geom_ribbon(data = pred_tdf1, 
              aes(time, y=NULL, col = NULL, 
                  ymin = pred_lo - pred, ymax = pred_hi-pred), alpha = .1)+ 
  scale_x_datetime(date_breaks = "1 year")
```


Pearson 

```{r}
pred_tdf1 %>% 
  ggplot(aes(time)) +
  geom_hline(yintercept = 0) + 
  geom_line(aes(y = pearson), col = 2, lwd=1)  +
  scale_x_datetime(date_breaks = "1 year") + 
  geom_hline(yintercept = c(-2,2)) + 
  ylim(c(-3,3))
```

nothing to report here. The odd ones are during period 2017-2019. 

### Odd ones

For reference, the stats for all monthly counts:

```{r}
rbind(obse= summary(temp_df$nobs),
      pred= summary(temp_df$pred)) %>%
  knitr::kable(digits=1)
                    
```

- we see that the observations are more heavy on the 0s

Check big residual times.

```{r}
oddtimes <- temp_df %>% filter(abs(pearson) > 2)
#oddones  <- mdf %>% filter( yearmonth %in% oddtimes$yearmonth)

knitr::kable(oddtimes, digits = 1)
```

- four instances

# Avaruus

Koko ajanjakso. Aggregoidaan data yli ajan, sitten verrataan ennusteisiin. Huomaa että tässä hila on aika rikkinäinen per ajanhetki, mutta pidetään se siten ennustettaessakin.

Elikkä yksikkö $i$ on 
$$n_i = \#\{susi \in C_i\}$$
where $C_i=month(i)x pixel(i)$ with 1x1km square pixels.

Ennuste on log-lineaarisen keskiarvon tasolla,

$$\hat\eta(i)$$

Josta ennuste tiheydelle 

$$\hat\lambda(i) = \exp[\hat\eta(i)]/|A_i|$$


Tehdään vielä aggregointi karkeampiin yksiköihin. 

```{r, cache=TRUE}
# Aggregointifunktio
make_spat_df <- function(mdf1, 
                         project_fun = sum) {

  cell_sum <- mdf1 %>% 
    group_by(raster_idx) %>% 
    summarise(nsusi = project_fun(nsusi), 
              npred = project_fun(pred))
  
  robs0 <- rpred0 <- raster(c20s)
  pixel_area <- prod( res(robs0) )
  
  robs0 [cell_sum$raster_idx]  <- cell_sum$nsusi
  rpred0[cell_sum$raster_idx]  <- cell_sum$npred 
  
  # crudify
  robs  <- aggregate(robs0,  fun = sum,  fact = 10)
  rpred <- aggregate(rpred0, fun = sum,  fact = 10)
  diff <- robs - rpred
  rpearson <- diff/sqrt(phihat * rpred)
 #cat( sprintf("square dimensions =%7.0fx%7.0fm\n", res(robs)[1], res(robs)[2]) )

# make a long df of the rasters.
  spat_df <- stack(list(obs=robs, pred=rpred, pearson = rpearson)) %>% 
    as.data.frame(xy=TRUE) %>%
    mutate(diff = obs - pred) %>%
    pivot_longer(cols = c(obs, pred, diff, pearson), names_to = "layer") %>%
    filter(!is.na(value))
  #
  list(robs = robs, rpred = rpred, pearson = rpearson, spat_df = spat_df)
}



## Full data:
L <- make_spat_df(mdf)
spat_df <- L$spat_df
robs <- L$robs
rpred <- L$rpred
rpearson <- L$pearson

spat_df %>% group_by(layer) %>% summarise(m = mean(value))

# by block
La <- make_spat_df(mdf %>% filter(vuosi < 2017))
Lb <- make_spat_df(mdf %>% filter(vuosi >= 2017))

spat_dfab <- bind_rows(La$spat_df %>% mutate(block = "before2017"),
                       Lb$spat_df %>% mutate(block = "from2017"))
```


Histograms of counts, rounded predictions: overall

```{r}
spat_df %>% filter(layer %in% c("obs", "pred")) %>%
  ggplot() +
  geom_histogram(aes( round(value) , 
                     fill = layer), position = position_dodge(), 
                 bins = 50)
```

and by pre-post 2017:

```{r}
spat_dfab %>% filter(layer %in% c("obs", "pred")) %>%
  ggplot() +
  geom_histogram(aes(round(value) , 
                     fill = layer), position = position_dodge(), 
                 bins = 50) +
  facet_wrap(~block, scale="free_y")
```

- 0 count is a bit overpresented


```{r, eval=TRUE, fig.height = 7, fig.width=9}
spat_df %>% filter( layer %in% c("obs", "pred")) %>%
  ggplot() +
  geom_raster(aes(x, y, fill = log(value+1) )) +
  scale_fill_distiller(palette = "Spectral") + 
  coord_fixed() +
  facet_wrap(~layer)
```


```{r, fig.height=5}
pd <- spat_df %>% filter(layer == "diff") %>%
  ggplot() +
  geom_raster(aes(x, y, fill = value )) +
  scale_fill_distiller(palette = "Spectral") + #, limits = c(-1,1)*20) + 
  coord_fixed() + ggtitle("obs - pred") 
pd
```


```{r, fig.height=5}
pdab <- spat_dfab %>% filter(layer == "diff") %>%
  ggplot() +
  geom_raster(aes(x, y, fill = value )) +
  scale_fill_distiller(palette = "Spectral") + #, limits = c(-1,1)*20) + 
  coord_fixed() + ggtitle("obs - pred")  + 
  facet_wrap(~block)
pdab
```




```{r, fig.height=5}
pp <- spat_df %>% filter(layer == "pearson") %>%
  ggplot() +
  geom_raster(aes(x, y, fill = abs(value) )) +
  scale_fill_distiller(palette = "Oranges", direction = 1) + 
  coord_fixed() + ggtitle("Pearson residuals") 
pp
```



```{r, fig.height=5}
ppab <- spat_dfab %>% filter(layer == "pearson") %>%
  ggplot() +
  geom_raster(aes(x, y, fill = abs(value) )) +
  scale_fill_distiller(palette = "Oranges", direction = 1) + 
  coord_fixed() + ggtitle("Pearson residuals")  +
  facet_wrap(~block)
ppab
```


Some pixels are way off.

```{r}
stat <- split(spat_df$value, spat_df$layer) %>% lapply(summary) %>% bind_rows(.id = "layer")
knitr::kable(stat, digits=2, caption = "Pearson residual")
```



## Extreme mismatches


```{r}
tassu <- readRDS("processed/tassu_dat2-v1.rds")
```


```{r}
i <- which.max(rpearson)

k <- cellFromXY(c20s, xyFromCell(robs, i))
rc <- rowColFromCell(c20s, k)
delta <- 5
kv <- cellFromRowColCombine(c20s, rc[1] + (-delta:delta),
                          rc[2] + (-delta:delta))

mdf_focus <- mdf %>% filter(raster_idx %in% kv)
mdf_focus_s <- mdf_focus %>% group_by(raster_idx) %>%
  summarise(nobs = sum(nsusi),
            pred = sum(pred), 
            pearson = (nobs-pred)/sqrt(phihat * pred),
            x = x[1], y=y[1])

mdf_focus_t <- mdf_focus %>% group_by(time, raster_idx) %>%
  summarise(nobs = sum(nsusi),
            pred = sum(pred), 
            pearson = (nobs-pred)/sqrt(phihat * pred),
            time = time,)

```

Marginal in space, one location:

```{r, fig.width=9, fig.height=8}
p <- mdf_focus_s %>% 
  ggplot() + 
  coord_fixed() + 
  scale_fill_distiller(palette = "Spectral") + 
  geom_tile(aes(x, y, fill = pearson))

p2 <- pp + geom_sf(data = mdf_focus_s %>% st_as_sf(coords=c("x","y"), crs=3067) %>% 
            st_bbox() %>% st_as_sfc(), fill=NA)

p2 + inset_element(p, left = 0.2, bottom = 0.5, right=1, top = 1)

```

And time:

```{r}
mdf_focus %>% ggplot() + 
    geom_jitter(aes(time, pearson,
                  shape = special_may))
```



```{r}
# Tassu points:
# cell_sum <- mdf %>% 
#     group_by(raster_idx) %>% 
#     summarise(nsusi = sum(nsusi), 
#               npred = sum(pred)) %>%
#   mutate(nsusi = replace(nsusi, nsusi == 0, NA))
# # 0 -> NA
#   
# mdf_focus_r <- mdf_focus_r_p <- raster(c20)
# mdf_focus_r[mdf_focus_s$raster_idx] <- mdf_focus_s$nobs
# mdf_focus_r <- crop( mdf_focus_r , extent(mdf_focus_s) + c(-1,1,-1,1)*500 )  
# mdf_focus_r_p <- setValues(mdf_focus_r, mdf_focus_s$pred)
# #mdf_focus_r  [cell_sum$raster_idx] <- cell_sum$nsusi
# #mdf_focus_r_p[cell_sum$raster_idx] <- cell_sum$npred
# mdf_focus_r_d <- mdf_focus_r - mdf_focus_r_p
# 
# 
# # only in focus area
# txy <- tassu %>% 
#   mutate(cell = cellFromXY(c20, cbind(x, y))) %>%
#   filter(cell %in% unique(mdf$raster_idx)) %>%
#   st_as_sf(coords = c("x", "y"), crs = crs(fin))
# 
# bbox <- st_bbox(mdf_focus_r) %>% st_as_sfc() %>% st_transform(crs = crs(fin))
# tassu_in_focus <- txy %>% 
#   mutate(in_focus = 
#            st_intersects(txy$geometry, bbox, sparse=FALSE)[,1] ) %>%
#   filter(in_focus)
```




```{r, eval=FALSE, fig.height=8}
library(leaflet)
# helpoin on vaihtaa objektien projektiot
mdf_focus_r1    <- projectRaster(mdf_focus_r,   crs = 4326)
mdf_focus_r_p1  <- projectRaster(mdf_focus_r_p, crs = 4326)
mdf_focus_r_d1  <- projectRaster(mdf_focus_r_d, crs = 4326)
tassu_in_focus1 <- st_transform(tassu_in_focus, crs = 4326)

pal  <- colorNumeric("Reds", values(mdf_focus_r1) %>% na.omit(), reverse = TRUE,
                    na.color = "transparent")
pal2 <- colorNumeric("Blues", values(mdf_focus_r_p1) %>% na.omit(), reverse = !TRUE,
                    na.color = "transparent")
pal3 <- colorNumeric("Greens", values(mdf_focus_r_d1) %>% na.omit(), reverse = !TRUE,
                    na.color = "transparent")
palc <- colorFactor("Set1", domain = tassu_in_focus1$havaintotyyppi)

lea  <- leaflet() %>% addTiles(group="base")

lea %>% 
  addRasterImage(mdf_focus_r1, colors = pal, opacity = .9, group = "havaitut") %>%
  addRasterImage(mdf_focus_r_p1, colors = pal2, opacity = .9, group = "ennuste") %>%
  addRasterImage(mdf_focus_r_d1, colors = pal3, opacity = .9, group = "ennuste-havaitut") %>%
  addCircleMarkers(data=tassu_in_focus1, col = ~palc(havaintotyyppi), 
                   group = "tassu", radius = 5, popup = ~aika, stroke = FALSE, fillOpacity = .7,
                   options = markerOptions(noHide = FALSE)) %>%
  addLegend(pal = pal, values = values(mdf_focus_r1), title = "observed counts 2010-2019") %>%
  addLegend(pal = pal2, values = values(mdf_focus_r_p1) %>% na.omit(), title = "predicted counts 2010-2019") %>%
  addLegend(pal = palc, values = tassu_in_focus1$havaintotyyppi, title = "havaintotyyppi") %>%
  addLayersControl(
                    overlayGroups = c("havaitut", "ennuste", "ennuste-havaitut", "tassu"), 
                   options = layersControlOptions(collapsed = FALSE))

```

```{r}
#lea %>% 
#leaflet() %>% addCircleMarkers(data=tassu_in_focus1 %>% sample_n(1000), col = ~palc(havaintotyyppi), 
#                   group = "tassu", radius = 5, popup = ~aika, stroke = FALSE, fillOpacity = 1) 
```

```{r}
La <- make_spat_df(mdf %>% filter(vuosi < 2017))
Lb <- make_spat_df(mdf %>% filter(vuosi >= 2017))

spat_dfab <- bind_rows(La$spat_df %>% mutate(block = "before2017"),
                       Lb$spat_df %>% mutate(block = "from2017"))

spat_dfab %>% group_by(layer, block) %>% summarise(m = mean(value))

```

Rounded predictions v observations.

```{r}
spat_dfab %>% filter(layer %in% c("obs", "pred")) %>%
  ggplot() +
  geom_histogram(aes(round(value), 
                     fill = layer), position = position_dodge(), 
                 bins = 50) + 
  facet_wrap(~block)
```

```{r, eval=TRUE, fig.height = 7, fig.width=9}
spat_dfab %>% filter(layer == "pearson") %>%
  ggplot() +
  geom_sf(data = fin1, fill=NA) + 
  geom_tile(aes(x, y, fill = value )) +
  scale_fill_distiller(palette = "Oranges", direction = 1) + 
  facet_wrap(~layer+block)
```

```{r}

```


## Omit largest observation?

Lets aggregate so that we omit the largest Tassu month when summing over time, before aggregating space pixels in the 10x10 neighbourhood.

```{r}
## Full data:
L2 <- make_spat_df(mdf, 
                   project_fun = function(x) sum( x[order(abs(x), decreasing=TRUE)[-1]] ))
L2a <- make_spat_df(mdf %>% filter(year < 2017), 
                   project_fun = function(x) sum( x[order(abs(x), decreasing=TRUE)[-1]] ))
L2b <- make_spat_df(mdf %>% filter(year >= 2017), 
                   project_fun = function(x) sum( x[order(abs(x), decreasing=TRUE)[-1]] ))


spat_df2 <- L2$spat_df
spat_df2ab <- bind_rows( L2a$spat_df %>% mutate(block = "before2017"),
                        L2b$spat_df %>% mutate(block = "from2017"))
```

```{r}
stat2 <- split(spat_df2$value, spat_df2$layer) %>% lapply(summary) %>% bind_rows(.id = "layer")
knitr::kable(stat2, digits=2, caption = "Pearson residual")
```


```{r, eval=TRUE, fig.height = 7, fig.width=9}
pp2 <- spat_df2 %>% filter(layer == "pearson") %>%
  ggplot() +
  geom_raster(aes(x, y, fill = value )) +
  scale_fill_stepsn(colors=c("blue", "gray90", "goldenrod"), 
                    breaks = seq(-3, 3, by = 1)) + 
  coord_fixed() + ggtitle("Pearson residuals") 
pp2
```

```{r, eval=TRUE, fig.height = 7, fig.width=9}
pp2ab <- spat_df2ab %>% filter(layer == "pearson") %>%
  ggplot() +
  geom_raster(aes(x, y, fill = value )) +
  scale_fill_stepsn(colors=c("blue", "gray90", "goldenrod"), 
                    breaks = seq(-3, 3, by = 1)) + 
  coord_fixed() + ggtitle("Pearson residuals") +
  facet_wrap(~block)
pp2ab
```




